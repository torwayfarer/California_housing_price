{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California Housing Price \n",
    "reference : exercise in chapter 2 of 'Hands-On Machine Learning with Scikit-learn and Tensorflow' by Aurélien Géron. \n",
    "\n",
    "##### Tip> shortcuts for Jupyter Notebook\n",
    "* Ctrl + Enter : run cell\n",
    "* Shift + Enter : run cell and select below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Load\n",
    "\n",
    "Load the data by using *read_csv()* method in __Pandas__ module. Then, let's take a look at the top 10 rows using the *head()* method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Data load\n",
    "import pandas as pd\n",
    "\n",
    "housing = pd.read_csv('housing.csv')\n",
    "housing.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the distribution of the data by using __matplotlib__ module briefly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figures plotting with data\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n",
    "    s=housing[\"population\"]/50, label=\"population\", figsize=(10,7),\n",
    "    c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n",
    "    sharex=False)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better understand the characteristics of each feature, let's apply the *info()* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check a structure of the data\n",
    "housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s look at how much each attribute correlates with the *median house value*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between the median_house_value and other features\n",
    "corr_matrix = housing.corr()\n",
    "corr_matrix['median_house_value'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare the Data\n",
    "\n",
    "this step consists of 'pre-processing', 'train-test seperation', and 'feature-label seperation'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1) Pre-processing \n",
    "\n",
    "#### 2-1.1) Data cleaning\n",
    "Most Machine Learning algorithms cannot work with missing features, so let’s replace the empty values of 'total_bedrooms' with the median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the empty values with the median\n",
    "median =housing[\"total_bedrooms\"].median()\n",
    "housing[\"total_bedrooms\"] = housing[\"total_bedrooms\"].fillna(median) \n",
    "housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1.2) Attributes combinations\n",
    "*rooms_per_household* is more meaningful than *total_rooms*. Also, *bedrooms_per_room* is more meaningful than *total_bedrooms*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes combinations\n",
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
    "del housing[\"total_rooms\"], housing[\"total_bedrooms\"]\n",
    "\n",
    "housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1.3) Feature Scaling\n",
    "Machine Learning algorithms don’t perform well when the input numerical attributes have very different scales.\n",
    "\n",
    "__Scikit-Learn__ provides a transformer called *StandardScaler* for *standardization*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# feature standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# delete columns of text type and target variable\n",
    "col_list = list(housing) \n",
    "col_list.remove('ocean_proximity') # text type\n",
    "col_list.remove('median_house_value') # target variable needs not to be scaled\n",
    "\n",
    "# generate a new dataframe that consist of numeric type only\n",
    "housing_numeric = housing[col_list]\n",
    "housing_scaled = scaler.fit_transform(housing_numeric)\n",
    "# Data type conversion from 'Series' to 'DataFrame'\n",
    "housing_scaled_df = pd.DataFrame(housing_scaled, index=housing_numeric.index, columns=housing_numeric.columns)\n",
    "\n",
    "# Concatenate \n",
    "housing = pd.concat([housing_scaled_df, housing['median_house_value'], housing['ocean_proximity']], axis=1)\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1.4) Handling Text and Categorical Attributes\n",
    "Most Machine Learning algorithms prefer to work with numbers anyway, so let’s convert the 'ocean_proximity' to numbers.\n",
    "\n",
    "__Pandas__ provides a *get_dummies* method to convert integer categorical values into one-hot vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "housing = pd.get_dummies(housing)\n",
    "housing.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2) Training and Test Set Seperation\n",
    "__Scikit-Learn__ provides *train_test_split* function to split dataset into multiple subsets in various ways. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training - test seperation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
    "\n",
    "print('# of train_set : %.0f, # of test_set : %.0f' %(train_set.shape[0], test_set.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3) Features and Target Value Seperation of the Training Set\n",
    "It’s time to prepare the data for your Machine Learning algorithms. \n",
    "\n",
    "Let’s separate the features and target value to generate the model H(X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature and label seperation of training set\n",
    "train_set_features = train_set.drop('median_house_value',axis=1)\n",
    "train_set_target = train_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Linear Regression\n",
    "generate the linear regression model by using *LinearRegression* function from __Scikit-learn__.\n",
    "\n",
    "For calculating our RMSE, *mean_square_error* function will be used from __scikit-learn__. Also, __numpy__ module will be used to use sqaure-root operation.\n",
    "\n",
    " $$RMSE = \\sqrt{\\sum{(y - \\widehat y)^2}\\over N}$$\n",
    " <br/>\n",
    " \n",
    "$y$ : actual median_house_value, $\\widehat y$ : median_house_value predicted. $N$ : total number of data<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE_calculation(param1, param2):\n",
    "    mse = mean_squared_error(param1, param2)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np # for a sqaure root calcuation\n",
    "\n",
    "# generate model by using training set\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(train_set_features, train_set_target) \n",
    "\n",
    "# Feature and target value Seperation of the test set\n",
    "test_set_features = test_set.drop('median_house_value',axis=1)\n",
    "test_set_target = test_set[\"median_house_value\"].copy()\n",
    "\n",
    "# target value predicted from our model\n",
    "train_final_predictions = lin_reg.predict(train_set_features)\n",
    "test_final_predictions = lin_reg.predict(test_set_features)\n",
    "\n",
    "# RMSE\n",
    "train_final_rmse = RMSE_calculation(train_set_target, train_final_predictions)\n",
    "test_final_rmse = RMSE_calculation(test_set_target, test_final_predictions)\n",
    "\n",
    "print('train_RMSE : %.2f , test_RMSE : %.2f' %(train_final_rmse, test_final_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Linear Regression with Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute matrix calculations easily, convert data types from dataframe to numpy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_features_array = train_set_features.values\n",
    "train_set_target_array =np.expand_dims(train_set_target,axis=1)\n",
    "\n",
    "test_set_features_array = test_set_features.values\n",
    "test_set_target_array = np.expand_dims(test_set_target,axis=1)\n",
    "\n",
    "train_y = train_set_target.values.reshape(-1,1)\n",
    "test_y = test_set_target.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the augmented matrix $X_{b}$ by adding bias column which consists of all 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bias_column = np.ones([train_set_features_array.shape[0],1])\n",
    "train_X_b = np.concatenate((train_set_features_array, train_bias_column),axis=1)\n",
    "\n",
    "test_bias_column = np.ones([test_set_features_array.shape[0],1])\n",
    "test_X_b = np.concatenate((test_set_features_array, test_bias_column),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1) Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient descent mothod is as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\theta \\leftarrow \\theta - \\eta\\nabla_{\\theta} J(\\theta) \\quad ,\\,where \\; \\eta = learning\\, rate$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\nabla_{\\theta} J(\\theta) = X^{T}X\\theta - X^{T}y $$\n",
    "$$ = X^{T}(X\\theta-y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is batch gradient descent that $X$ contains all training instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, initialize $\\theta$ and store the training RMSE and validation RMSE for this initialized $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize theta \n",
    "feature_num = train_X_b.shape[1]\n",
    "theta = np.random.randn(feature_num,1)\n",
    "\n",
    "GD_train_rmse = []\n",
    "GD_val_rmse = []\n",
    "\n",
    "initialized_theta_train_RMSE = RMSE_calculation(np.dot(train_X_b,theta), train_y)\n",
    "initialized_theta_val_RMSE = RMSE_calculation(np.dot(test_X_b,theta), test_y)\n",
    "\n",
    "GD_train_rmse.append(initialized_theta_train_RMSE)\n",
    "GD_val_rmse.append(initialized_theta_val_RMSE)\n",
    "\n",
    "print('RMSE of the initialized theta - train_RMSE : %.2f, val_RMSE : %.2f' %(initialized_theta_train_RMSE, initialized_theta_val_RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute your batch gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_num = train_X_b.shape[0]\n",
    "\n",
    "batch_size = train_num\n",
    "n_epoch = 10000\n",
    "eta = 0.001 # learning rate\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    gradient = 2.0 / batch_size * np.dot(train_X_b.T , np.dot(train_X_b, theta) - train_y)\n",
    "    theta = theta - eta * gradient\n",
    "    \n",
    "    # train error\n",
    "    GD_train_predictions = np.dot(train_X_b, theta)\n",
    "    GD_train_final_rmse = RMSE_calculation(train_y, GD_train_predictions)\n",
    "    GD_train_rmse.append(GD_train_final_rmse)\n",
    "    \n",
    "    # val error\n",
    "    GD_val_predictions = np.dot(test_X_b, theta)\n",
    "    GD_val_final_rmse = RMSE_calculation(test_y, GD_val_predictions)\n",
    "    GD_val_rmse.append(GD_val_final_rmse)\n",
    "    \n",
    "    if epoch%100 == 0:\n",
    "        print('%d번째 train_RMSE : %.2f, val_RMSE : %.2f' %(epoch, GD_train_final_rmse, GD_val_final_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for changes of RMSE as epoch increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(GD_train_rmse, \"r+\", linewidth=2, label=\"train\")\n",
    "plt.plot(GD_val_rmse, \"b-\", linewidth=3, label=\"val\")\n",
    "\n",
    "plt.ylim([60000, 250000])\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2) Mini-Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is mini-batch gradient descent that  𝑋  contains only a small set of randomly selected training instances.<br/>\n",
    "It is important to shuffle the order of train instances after each epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize  𝜃  and store the training RMSE and validation RMSE for this initialized  𝜃 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.random.randn(feature_num,1)\n",
    "theta_bkp = theta # back-up the theta values\n",
    "\n",
    "GD_train_rmse = []\n",
    "GD_val_rmse = []\n",
    "\n",
    "GD_batch_train_rmse = []\n",
    "GD_batch_val_rmse = []\n",
    "\n",
    "initialized_theta_train_RMSE = RMSE_calculation(np.dot(train_X_b,theta), train_y)\n",
    "initialized_theta_val_RMSE = RMSE_calculation(np.dot(test_X_b,theta), test_y)\n",
    "\n",
    "GD_train_rmse.append(initialized_theta_train_RMSE)\n",
    "GD_val_rmse.append(initialized_theta_val_RMSE)\n",
    "GD_batch_train_rmse.append(initialized_theta_train_RMSE)\n",
    "GD_batch_val_rmse.append(initialized_theta_val_RMSE)\n",
    "\n",
    "print('RMSE of the initialized theta - train_RMSE : %.2f, val_RMSE : %.2f' %(initialized_theta_train_RMSE, initialized_theta_val_RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute your mini-batch gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_epoch = 100\n",
    "eta = 0.001 # learning rate\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    \n",
    "    # shuffle\n",
    "    shuffle_indices = np.random.permutation(train_num)\n",
    "    feature_shuffled = train_X_b[shuffle_indices,:]\n",
    "    target_shuffled = train_y[shuffle_indices,:]\n",
    "    \n",
    "    for i in range(0, train_num, batch_size):\n",
    "        batch_x = feature_shuffled[i:i+batch_size,:]\n",
    "        batch_y = target_shuffled[i:i+batch_size,:]\n",
    "\n",
    "        gradient = 2.0/batch_size * np.dot(batch_x.T , np.dot(batch_x, theta) - batch_y)\n",
    "        theta = theta - eta * gradient\n",
    "        \n",
    "        # train error after batch update \n",
    "        train_batch_predictions = np.dot(train_X_b, theta)\n",
    "        train_batch_rmse = RMSE_calculation(train_y, train_batch_predictions)\n",
    "        GD_batch_train_rmse.append(train_batch_rmse)\n",
    "        \n",
    "        # test error after batch update\n",
    "        val_batch_predictions = np.dot(test_X_b, theta)\n",
    "        val_batch_rmse = RMSE_calculation(test_y, val_batch_predictions)\n",
    "        GD_batch_val_rmse.append(val_batch_rmse)\n",
    "        \n",
    "    # train error after epoch \n",
    "    GD_train_predictions = np.dot(train_X_b, theta)\n",
    "    GD_train_final_rmse = RMSE_calculation(train_y, GD_train_predictions)\n",
    "    GD_train_rmse.append(GD_train_final_rmse)\n",
    "    \n",
    "    # val error after epoch \n",
    "    GD_val_predictions = np.dot(test_X_b, theta)\n",
    "    GD_val_final_rmse = RMSE_calculation(test_y, GD_val_predictions)\n",
    "    GD_val_rmse.append(GD_val_final_rmse)\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print('%d번째 train_RMSE : %.2f, val_RMSE : %.2f' %(epoch, GD_train_final_rmse, GD_val_final_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for changes of RMSE as epoch increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(GD_train_rmse, \"r+\", linewidth=2, label=\"train\")\n",
    "plt.plot(GD_val_rmse, \"b-\", linewidth=3, label=\"val\")\n",
    "\n",
    "plt.ylim([60000, 250000])\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for changes of RMSE as the number of updates increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(GD_batch_train_rmse, \"r+\", linewidth=2, label=\"train\")\n",
    "plt.plot(GD_batch_val_rmse, \"b-\", linewidth=3, label=\"val\")\n",
    "\n",
    "plt.ylim([60000, 250000])\n",
    "plt.xlim([0,2000])\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('updates')\n",
    "plt.ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-3) Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is stochastic gradient descent that $𝑋$ contains only one training instance selected randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize 𝜃 and store the training RMSE and validation RMSE for this initialized 𝜃 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.random.randn(feature_num,1)\n",
    "theta_bkp = theta # back-up the theta values\n",
    "\n",
    "GD_train_rmse = []\n",
    "GD_val_rmse = []\n",
    "\n",
    "GD_batch_train_rmse = []\n",
    "GD_batch_val_rmse = []\n",
    "\n",
    "initialized_theta_train_RMSE = RMSE_calculation(np.dot(train_X_b,theta), train_y)\n",
    "initialized_theta_val_RMSE = RMSE_calculation(np.dot(test_X_b,theta), test_y)\n",
    "\n",
    "GD_train_rmse.append(initialized_theta_train_RMSE)\n",
    "GD_val_rmse.append(initialized_theta_val_RMSE)\n",
    "GD_batch_train_rmse.append(initialized_theta_train_RMSE)\n",
    "GD_batch_val_rmse.append(initialized_theta_val_RMSE)\n",
    "\n",
    "print('RMSE of the initialized theta - train_RMSE : %.2f, val_RMSE : %.2f' %(initialized_theta_train_RMSE, initialized_theta_val_RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute your stochastic gradient descent algorithm.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Q1. ##################################\n",
    "#  TO DO : Fill in the blank with your stochastic gradient descent code.\n",
    "# set the hyper-parameters as follows.\n",
    "# parameters setting : batch size = 1 , epoch = 50 , learning rate = 0.001\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    ######################## Q2. ##################################\n",
    "    \n",
    "    \n",
    "    ##############################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Q3. ##################################\n",
    "# TO DO : plot the learning curve of each epoch.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Q4. ##################################\n",
    "# TO DO : plot the learning curve of each updates.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-4) Stochastic Gradient Descent using SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn provides a function for stochastic gradient descent, SGDRegressor().<br/>\n",
    "SGDRegressor() has 2 methods, 'fit()' and 'partial_fit()'. <br/>\n",
    "If you use 'fit()' method, you can check the RMSE after total epoches. In the case of 'partial_fit()' method, you can check the RMSE of each epoch.<br/>\n",
    "To plot the changes of RMSE depending on each epoch, please use 'partial_fit()' method.<br/>\n",
    "\n",
    "reference : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGDfunc_train_rmse = []\n",
    "SGDfunc_val_rmse = []\n",
    "\n",
    "SGDfunc_initialized_theta_train_RMSE = RMSE_calculation(np.dot(train_X_b,theta_bkp), train_y)\n",
    "SGDfunc_initialized_theta_val_RMSE = RMSE_calculation(np.dot(test_X_b,theta_bkp), test_y)\n",
    "\n",
    "SGDfunc_train_rmse.append(SGDfunc_initialized_theta_train_RMSE)\n",
    "SGDfunc_val_rmse.append(SGDfunc_initialized_theta_val_RMSE)\n",
    "\n",
    "\n",
    "print('RMSE of the initialized theta - train_RMSE : %.2f, val_RMSE : %.2f' \n",
    "      %(SGDfunc_initialized_theta_train_RMSE, SGDfunc_initialized_theta_val_RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the blanks with your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "######################## Q1. ##################################\n",
    "#  TO DO : import SGDRegressor() function.\n",
    "from sklearn.linear_model \n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "######################## Q2. ##################################\n",
    "# TO DO : set the number of n_epoch to 50\n",
    "n_epoch = \n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "######################## Q3. ##################################\n",
    "# TO DO : set the parameters of SGDRegressor() as follows.\n",
    "# parameters setting : penalty='none', learning_rate='constant', eta0=0.001\n",
    "\n",
    "SGD_model = \n",
    "##############################################################\n",
    "\n",
    "\n",
    "for epoch in range(n_epoch):   \n",
    "    ######################## Q4. ##################################\n",
    "    # TO DO : execute 'partial_fit()' method.\n",
    "    \n",
    "    ##############################################################\n",
    "    \n",
    "    # train error\n",
    "    SGD_train_predictions = SGD_model.predict(train_set_features)\n",
    "    SGD_train_final_rmse = RMSE_calculation(SGD_train_predictions, train_set_target)\n",
    "    SGDfunc_train_rmse.append(SGD_train_final_rmse)\n",
    "    \n",
    "    # val error\n",
    "    SGD_val_predictions = SGD_model.predict(test_set_features)\n",
    "    SGD_val_final_rmse = RMSE_calculation(SGD_val_predictions, test_set_target)\n",
    "    SGDfunc_val_rmse.append(SGD_val_final_rmse)\n",
    "    \n",
    "    if epoch%5 == 0:\n",
    "           print('%d번째 train_RMSE : %.2f, val_RMSE : %.2f' %(epoch, SGD_train_final_rmse, SGD_val_final_rmse))\n",
    "\n",
    "    # command to hide the warning box\n",
    "    import warnings\n",
    "    warnings.filterwarnings(action = 'ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Q5. ##################################\n",
    "# TO DO : plot the learning curve as epoch changes.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
